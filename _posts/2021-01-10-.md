---
layout: post
title: "ê°•í™”í•™ìŠµ"
date: 2021-01-09
categories: Reinforcement_Learning
tags: [Reinforcement Learning, MDP, Dynamic Programming]
---



# ê°•í™”í•™ìŠµì´ë€?



* í–‰ë™ì‹¬ë¦¬í•™ì—ì„œ **ê°•í™”** ê°œë… ì²˜ìŒ ë“±ì¥

  > ë™ë¬¼ì´ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²•  (ê°•í™”ì‹¤í—˜: ìŠ¤í‚¤ë„ˆì˜ ì¥ ì‹¤í—˜)
  >
  > ğŸ­: ìƒì¥ê°€ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ ì§€ë ›ëŒ€ì™€ ì¹˜ì¦ˆ ì‚¬ì´ì˜ ê´€ê³„ í•™ìŠµ
  >
  > [ğŸ‘¨â€ğŸ’»](https://www.emojiall.com/ko/emoji/ğŸ‘¨â€ğŸ’») : ì—ì´ì „íŠ¸ê°€ ì‹œí–‰ì°©ì˜¤ë¥¼ í†µí•´ í–‰ë™ê³¼ ë³´ìƒ ì‚¬ì´ì˜ ê´€ê³„ í•™ìŠµ

* ê°•í™”í•™ìŠµì˜ ëª©ì ì€ **ë³´ìƒ**ì„ ìµœëŒ€í•œ ë§ì´ ë°›ëŠ” **ìµœì  ì •ëµ(ì •ì±…)**ì„ ì§œëŠ” ê²ƒ

* ì •ì±…ì´ë€:
  í˜„ì¬ ìƒíƒœì—ì„œì˜ í–‰ë™ì— ëŒ€í•œ í•¨ìˆ˜
  ![image-20210105232356420](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210105232356420.png) 

* **ìµœì  ì •ì±…**ì´ë€:
  ë¯¸ë˜ ë°›ì„ ìˆ˜ ìˆëŠ” **ëˆ„ì  ë³´ìƒì„ ìµœëŒ€í™”** í•˜ëŠ” **ì •ì±…**

* ìµœì  ì •ì±… ì°¾ëŠ” ë°©ë²•:

  1. ê¸°ì¡´ ì •ì±… **í‰ê°€**
  2. ê¸°ì¡´ ì •ì±… **ê°œì„ **
  3. 1,2 ë°˜ë³µ

  * ì •ì±… í‰ê°€ ì§€í‘œ: **Value Function(ê°€ì¹˜ í•¨ìˆ˜)**

* ì •ì±…ì„ í‰ê°€í•˜ëŠ” Value Functionì„ ì°¾ëŠ” ë°©ë²•

  - ê°•í™”í•™ìŠµ ë¬¸ì œ ìˆ˜í•™ì  ì •ì˜ í•„ìš”
  - ê°•í™”í•™ìŠµ ë¬¸ì œ == ìˆœì°¨ í–‰ë™ ê²°ì • ë¬¸ì œ
  - ìˆœì°¨ í–‰ë™ ê²°ì • ë¬¸ì œ í•´ê²°ë²• == ë§ˆë¥´ì½”í”„ ê²°ì • í”„ë¡œì„¸ìŠ¤



# ë§ˆë¥´ì½”í”„ ê²°ì • í”„ë¡œì„¸ìŠ¤ (MDP)

* ì •ì˜: ê°•í™”í•™ìŠµ **í™˜ê²½**ì˜ **ìˆ˜í•™ì  ì •ì˜**
* í•„ìš” ì´ìœ 
  - ì •ì±…ì„ í‰ê°€í•˜ëŠ” **Value Function**ê³„ì‚°

* 5ê°€ì§€ ìš”ì†Œ

  1. State(ìƒíƒœ)

     - ì—ì´ì „íŠ¸ê°€ ë‹¤ìŒ **í–‰ë™ ê²°ì •** ì‹œ , **í•„ìˆ˜ ì •ë³´**

     - **ë§ˆë¥´ì½”í”„ íŠ¹ì„±** :  ê³¼ê±° ìƒíƒœ ì •ë³´ëŠ” í˜„ì¬ ìƒíƒœì— í¬í•¨ or ì‚¬ìš© X

  2. Action(í–‰ë™)

     - ì—ì´ì „íŠ¸ê°€ **í•  ìˆ˜ ìˆëŠ” í–‰ë™**

  3. Reward (ë³´ìƒ)

     - ì—ì´ì „íŠ¸ê°€ **í–‰ë™í•¨ìœ¼ë¡œì¨ ì–»ê²Œ ë˜ëŠ” ë³´ìƒ**

  4. Transition Probability (ì „ì´ í™•ë¥ )

     - ì—ì´ì „íŠ¸ê°€ í–‰ë™ ì‹œ, **íŠ¹ì • ìƒíƒœë¡œ ê°ˆ í™•ë¥ **

  5. Discount Factor(í• ì¸ ìš”ì†Œ)

     - ì—ì´ì „íŠ¸ê°€ ë°›ì„ **ë³´ìƒì˜ ë³€í™”**



### **Value Function** 

- ê°€ì¹˜ í•¨ìˆ˜(Value Function)
  * **í˜„ ìƒíƒœ**ì—ì„œ **ì—ì´ì „íŠ¸**ê°€ **ì •ì±…**ì„ ë”°ë¥¼ ê²½ìš°, **ë¯¸ë˜ ë³´ìƒ**ë“¤ì˜ **ê¸°ëŒ“ê°’**

* êµ¬í•˜ëŠ” ë°©ë²• 

  EX) ìƒì¥ê°€ ìµœëŒ€í•œ ì¹˜ì¦ˆë¥¼ ë§ì´ ë¨¹ê¸° ìœ„í•œ ì •ì±…ì˜ ê°€ì¹˜í•¨ìˆ˜

  - Value Function ë†’ìŒ -> ë¨¹ì„ ìˆ˜ ìˆëŠ” ì¹˜ì¦ˆë“¤ì˜ í‰ê·  ê°œìˆ˜ ë†’ìŒ -> ì¢‹ì€ ì •ì±…

  - Value Function ë‚®ìŒ -> ë¨¹ì„ ìˆ˜ ìˆëŠ” ì¹˜ì¦ˆë“¤ì˜ í‰ê·  ê°œìˆ˜ ë‚®ìŒ -> ë‚˜ìœ ì •ì±…

    => í˜„ì¬ ìƒì¥ê°€ **ì •ì±…**ì„ ë”°ë¥¸ ê²½ìš° ë¨¹ì„ ìˆ˜ ìˆëŠ” **ì¹˜ì¦ˆ í‰ê·  ê°œìˆ˜**

  ![image-20210108202643254](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108202643254.png)![image-20210108202730684](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108202730684.png)

   ![image-20210108202936341](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108202936341.png)![image-20210108203027995](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108203027995.png)

  ![image-20210108213032157](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108213032157.png)

  ### **Bellman Equation**

  : **Value Function íŠ¹ì„±** ì´ìš©í•˜ì—¬ ë˜‘ë˜‘í•˜ê²Œ **Value Function**ì„ êµ¬í•¨
  ![image-20210108213309044](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108213309044.png)

  * ë°©ë²•: í˜„ì¬ ìƒíƒœ(S)ì˜ Value Functionì€ ë‹¤ìŒ ìƒíƒœ (S')ì˜ Value Functionì„ ì‚¬ìš©í•´ í‘œí˜„
    ![image-20210108213755581](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108213755581.png)

  * í–‰ë ¬ì„ í’€ì–´ ëª¨ë“  Value Functionì„ êµ¬í•¨
    ![image-20210108214311740](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210108214311740.png)
  * ë‹¨ì  : 
    í–‰ë ¬ ì‚¬ìš©í•´ Value Functionì„ êµ¬í•  ì‹œ, ê³„ì‚°ëŸ‰ ì¦ê°€(Stateê°€ ë¬´í•œ...)
  * ì†”ë£¨ì…˜:
    Iterativeí•œ ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ í•´ê²°(Gradient Descentì™€ ìœ ì‚¬)







# Planing by Dynamic Programming



### **Bellman Equationê³¼ Dynamic Programming**

* **Bellman Equation** : ![image-20210116210619554](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210116210619554.png)
  * í˜„ì¬ ìƒíƒœ(S)ì˜ Value Functionì€ ë‹¤ìŒ ì‹œì (S')ì˜ Value Functionì„ ì‚¬ìš©í•´ ì—…ë°ì´íŠ¸ ê°€ëŠ¥
  * ì•„ì´ë””ì–´: Bellman Equationì„ ê³„ì† ì—…ë°ì´íŠ¸  ì‹œ, ì‹¤ì œ Value Functionì„ êµ¬í•  ìˆ˜ ìˆìŒ(ì¦ëª…)
    ![image-20210116210818913](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210116210818913.png)
* **Dynamic Programming** : ê²°ê³¼ë¥¼ ì ì–´ ë†“ê³ , ë¬¸ì œ í•´ê²°í•˜ëŠ” ë°©ë²•
  * DP ì‚¬ìš© ì´ìœ  : Value Functionì€ ê³„ì† ì‚¬ìš© ë¨ -> DPë¥¼ ì‚¬ìš©í•˜ì!





### **DPí™œìš©, Value Function ì°¾ê¸°**

![image-20210117011331609](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210117011331609.png)



![image-20210117011429018](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210117011429018.png)



### **Value Function ì°¾ì€ í›„ Policy ê°œì„ **

* Policy ê°œì„  ë°©ë²•
  * Value Function ìˆ˜ë ´ ì‹œ ê¹Œì§€ ë°˜ë³µ -> policy í‰ê°€ (Evaluation)
  * Value Function **ì°¸ê³ , ìƒì¥ ì •ì±… ê°œì„ **

![image-20210117012133600](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210117012133600.png)



* ê°œì„  ë°©í–¥ (New Policy)

![image-20210117012147608](C:\Users\com11\AppData\Roaming\Typora\typora-user-images\image-20210117012147608.png)



### Policy Iterationì´ë€?

* Policy í‰ê°€ì™€ ê°œì„ (Policy Iteration)
  * 1. ê¸°ì¡´ Policyë°”íƒ•ìœ¼ë¡œ Value Function ê³„ì‚°(Policy Evaluation)
  * 2. Value Functionì„ ì´ìš©í•˜ì—¬, Policy ê°œì„ (Policy Improvement)
  * Policyê°€ 