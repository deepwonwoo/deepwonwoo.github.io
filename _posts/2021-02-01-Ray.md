---
layout: post
title: "Ray"
date: 2021-02-01
categories: Python
tags: [Data science, Python, Ray]
---



![https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png](https://github.com/ray-project/ray/raw/master/doc/source/images/ray_header_logo.png)

# **Ray**

: 머신러닝 엔지니어링에서 필요한 확장가능한 시스템을 구축할 수 있도록 하며, 효과적이고 단순하게 분산/병렬 컴퓨팅을 수행할 수 있도록 만든 매우 강력한 프레임워크입니다. 이러한 강점으로 아직 정확한 체계가 잡히지 못한 머신러닝 엔지니어링이라는 분야의 초석이 되기에 부족함이 없는 강력한 도구입니다.

* 버클리 대학의 RISE 연구실에서 만들고, 최근에 연구실분들이 [AnyScale](https://www.anyscale.com/)라는 회사를 설립해 Ray를 사용한 프러덕트를 만들고 있음

* 최근에 핫한 라이브러리로 머신러닝/딥러닝을 위해 개발되었지만 다양하게 활용할 수 있음

- 분산 어플리케이션을 만들기 위해 단순하고 범용적인 API를 제공하는 라이브러리
- **기존에 작성한 코드를 조금만 추가해서 병렬처리를 할 수 있는 점이 큰 장점!**
- Process 기반으로 분산처리, 병렬처리를 진행함



## Ray의 3가지 미션

- 1) 분산 어플리케이션을 빌드, 실행하기 위한 기본 요소 제공
- 2) 아주 적은 코드 변경으로 병렬화할 수 있음
- 3) Ray Core를 기반으로 여러 애플리케이션 존재. 대규모 에코 시스템 구축



## Ray의 장점

1) 기존 코드에서 약간의 수정만으로 병렬 처리 가능 : 쉽고 범용적인 사용성

- 처음엔 병렬처리 생각하지 않고 코드 구현 후, 마지막에 병렬로 구현
- 함수에 데코레이터로 `@ray.remote`로 감싸기
- 클래스도`@ray.remote`로 감싸기
  - 혹은 ray.remote(클래스)로 사용할 수도 있음

2) Dashboard가 존재해서 성능, 로그 등을 확인 가능

3) 멀티프로세싱보다 빠른 성능

4) 머신러닝/딥러닝에서 활용하기 최적

- 머신러닝/딥러닝 외에서도 활용 가능(크롤링 병렬처리, 최적화 병렬처리 등)

5) 풍부한 생태계

- 강화학습을 위한 RLLib
- 하이퍼파라미터 튜닝을 위한 Ray Tune
- 분산 학습을 위한 Ray SGD
- Serving을 위한 Ray Serve
- 그 외에 Dask, Horovod, Hugging Face, Modin, PyCaret, Scikit Learn, Spacy, XGBoost, Seldon Alibi 등 다른 라이브러리와 활발하게 성장 중

6) Nested하게 실행 가능

- Ray Task의 호출 결과로 여러 Task가 생성될 수 있음



## Ray 구성 요소

 처음 Ray를 접할 때는 크게 Task, Actor, Object, Driver, Job 정도만 이해해도 충분함

(그 이후에 내부가 궁금하면 Node, Worker, Scheduler, Global Control Store 등에 대해 파악해보기)



### Task(Remote Function)

- 호출하는 곳과 다른 프로세스에서 실행되는 함수
- 함수를 @ray.remote로 감싼 경우를 Task라 지칭
  - Remote Function이라고 부르는 경우도 있음
- 호출할 경우 Task가 비동기(asynchoronously)하게 실행됨
- `.remote()`를 호출하면 Future 객체(ObjectRef)를 반환
- `ray.get(ObjectRef)`를 할 경우 Task가 실행됨
- @ray.remote로 감싼 함수의 경우 stateless하고, @ray.remote로 감싼 클래스(Actor)의 Task는 stateful함
- 사용 방식
  - 함수를 작성하고(예 : say_hello 함수)
  - 함수에 데코레이터로 @ray.remote로 감싸고
  - 함수 호출은 say_hello.remote()
  - 값 반환은 ray.get(say_hello.remote())



### Actor

- Stateful한 워커
- @ray.remote로 감싼 파이썬 클래스 인스턴스



### Object

- 어플리케이션의 value
- Task를 통해 반환되거나 `ray.put()` 을 통해 생성
  - 사용 예시 : Pandas 데이터프레임을 Object로 만들어서 Ray 워커에서 사용하곤 함
- Object는 immutable하며 한번 생성되면 수정되지 않음(스파크의 RDD처럼)



### Driver

- 프로그램의 메인 루트
- `ray.init()`을 호출하면 실행



### Job

- 동일한 드라이버에서 발생한 Task, Actor, Object의 컬렉션





## 자주 사용하는 API 정리

  

- 위에서 설명하진 않았지만 알아두면 좋은 `ray.put()`, `ray.wait()`, `ray.shutdown()`도 정리함
- 참고로 ray.put()는 큰 배열을 공유 메모리에 저장하고 복사본을 만들지 않고 모든 작업자에 프로세스에 액세스 할 수 있음
  - 복사를 하지 않으니 메모리를 아낄 수 있음

![img](https://www.dropbox.com/s/1pnke3phden1f70/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-03%20%EC%98%A4%ED%9B%84%204.17.36.png?raw=1)





## Ray Dashboard

 

- Ray의 대시보드의 역할

  - 클러스터 지표 확인
    - 클러스터 이상을 감지하고 디버깅
  - 로그 및 오류를 확인할 수 있음
  - 여러 머신의 로그를 한번에 확인할 수 있음
  - Ray 메모리 사용률, 디버그 메모리 오류들을 확인할 수 있음
  - Actor별 리소스 사용량, 실행된 Task, 로그 등을 확인
  - Actor를 Kill하고 Ray Job을 프로파일링

- Ray 사용법에서 나온 코드를 실행한 후, `localhost:8265`로 이동하면 대시보드가 보임

  - 포트를 수정하고 싶은 경우 ray.init()에서 dashboard_port 인자 값을 수정하면 됨
    ![img](https://www.dropbox.com/s/ng8lbi4x4c1cmn4/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-03%20%EC%98%A4%ED%9B%84%204.19.59.png?raw=1)

- Ray Dashboard 구성
  - Machine View : 리소스 사용량 확인, 로그/에러 확인
  - Logical View : Ray 클러스터에서 실행 중인 Actor 모니터링(클러스터가 아닌 경우 아무것도 뜨지 않음)
  - Memory : Ray Object Store에 저장된 정보를 볼 수 있음
  - Ray config : Ray 클러스터 설정
  - TUNE(이건 Ray Core만 실행할 시 보이지 않음)

- 현재 프로세스가 8개가 보이는데, 이는 제 실행 환경의 CPU가 8 Core라서 이렇게 보임(ray.init시 CPU 갯수를 설정할 수 있음)

- 프로세스별 CPU, Memory, GPU 사용량을 볼 수 있음

  - Plasma는 위에서 설명하지 않았지만, Object를 저장해두는 Object Store
  - 더 궁금할 경우 [The Plasma In-Memory Object Store](https://arrow.apache.org/docs/python/plasma.html#the-plasma-in-memory-object-store) 참고

- 우측에 Logs를 보면 전체 로그와 프로세스별 로그를 확인할 수 있음

  - 아래 이미지는 View all logs를 클릭한 경우

  ![img](https://www.dropbox.com/s/bhqfw2efh3zo167/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-01-03%20%EC%98%A4%ED%9B%84%204.25.20.png?raw=1)




## 처음 사용하는 사람들을 위한 Tip

 1) `ray.get()`은 실행 횟수 파악하기(가능하면 늦게 호출)

- 다음과 같이 remote를 하며 호출하는 경우는 느림

  - 예시(List Comprehension하며 ray.get을 반복 호출)

    ```
      results = [ray.get(do_some_work.remote(x)) for x in range(4)]
    ```

- 빠른 예시(List Comprehension 결과를 ray.get으로 받아 1번만 호출)

  ```
    results = ray.get([do_some_work.remote(x) for x in range(4)])
  ```



2) CPU가 적거나 클러스터가 적은 상황에선 성능 개선이 크지 않을 수 있음

- 테스트는 여러 환경에서 할 수 있도록 Test 자동화 필요

3) 작은 함수를 모두 Task로 만들 필요 없음

- 스케줄링, 내부 프로세스 커뮤니케이션 등에 오버헤드가 걸릴 수 있음
- 큰 Task를 생성해서 작은 함수를 여러번 실행하도록 만들어서 성능 개선할 수 있음

4) 반복되고 큰 데이터의 경우 ray.put으로 저장한 후 활용하기

- 단 1번만 object store에 저장해서 반복적으로 접근하지 않음

- 데이터를 그냥 사용하는 경우

  ```
    import time
    import numpy as np
    import ray
  		
    ray.init(num_cpus = 4)
  		
    @ray.remote
    def no_work(a):
        return
  		
    start = time.time()
    a = np.zeros((5000, 5000))
    result_ids = [no_work.remote(a) for x in range(10)]
    results = ray.get(result_ids)
    print("duration =", time.time() - start)
    # duration = 1.0837509632110596
  ```

- 데이터를 ray.put으로 저장한 후 사용하는 경우

  ```
    import time
    import numpy as np
    import ray
  		
    ray.init(num_cpus = 4)
  		
    @ray.remote
    def no_work(a):
        return
  		
    start = time.time()
    a_id = ray.put(np.zeros((5000, 5000)))
    result_ids = [no_work.remote(a_id) for x in range(10)]
    results = ray.get(result_ids)
    print("duration =", time.time() - start)
    # duration = 0.132796049118042
  ```